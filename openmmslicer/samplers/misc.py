from cached_property import cached_property as _cached_property
import cachetools as _cachetools
import collections as _collections
from itertools import groupby as _groupby
import math as _math
import threading as _threading

import numpy as _np
import pandas as _pd

from openmmslicer.interpolate import BatchLinearInterp as _BatchLinearInterp


class LinearAlchemicalFunction:
    """
    An object which handles the description of alchemical functions and how their energies are interpolated when
    evaluated in the context of free energy calculations.

    Parameters
    ----------
    start : float
        The lambda value at and below which the function will have a value of 0.
    end : float
        The lambda value at and above which the function will have a value of 1.
    full_interpolation : bool, optional
        If True, every protocol lambda value between the start and end point will be used for interpolation. This
        should only be set to False if the interactions are linearly coupled. Default is True.
    extra_interpolation_points : list, optional
        These points are always used for interpolation, regardless of the value of full_interpolation or the alchemical
        protocol.

    Attributes
    ----------
    start : float
        The lambda value at and below which the function will have a value of 0.
    end : float
        The lambda value at and below which the function will have a value of 0.
    boundaries : tuple
        Equivalent to (start, end).
    """
    def __init__(self, start, end, full_interpolation=True, extra_interpolation_points=None):
        self.boundaries = start, end
        self.full_interpolation = full_interpolation
        if extra_interpolation_points is None:
            extra_interpolation_points = []
        self.extra_interpolation_points = extra_interpolation_points

    @property
    def boundaries(self):
        return self._start, self._end

    @property
    def start(self):
        return self._start

    @property
    def end(self):
        return self._end

    @boundaries.setter
    def boundaries(self, val):
        if not isinstance(val, tuple) or len(val) != 2 or val[0] >= val[1] or any(not 0 <= x <= 1 for x in val):
            raise ValueError("Need to supply a valid tuple with two ordered values between 0 and 1")
        self._start, self._end = val

    def __call__(self, x):
        """
        Evaluates the alchemical function.

        Parameters
        ----------
        x : float
            The value at which to evaluate the LinearAlchemicalFunction.

        Returns
        -------
        y : float
            The evaluated LinearAlchemicalFunction.
        """
        if x <= self._start:
            return 0.
        elif x >= self._end:
            return 1.
        else:
            return (x - self._start) / (self._end - self._start)


class Walker:
    """
    A container used for the description of an alchemical state and caching its energies at different lambda values.

    Parameters
    ----------
    name : any
        An identifier for the walker.
    kwargs
        Any other attributes to be set.

    Attributes
    ----------
    name : any
        The walker name.
    state : openmm.State
        The corresponding OpenMM State.
    original_lambda_ : float
        The lambda value at which the walker was generated.
    lambda_ : float
        The current lambda value of the walker.
    iteration : int
        The iteration during which this walker was generated at a particular lambda value.
    transform : list
        Transforms applied to the state, generated by openmmslicer.moves.MoveList.generate().
    reporter_filename : str
        The path to the trajectory file where the state has been written.
    frame : int
        The corresponding frame of the trajectory file where this state has been written.
    logW : float
        The logarithm of the relative weight of the walker.
    """
    _reset_cache_triggers = ["state", "lambda_", "transform", "reporter_filename", "frame"]

    def __init__(self, name, state=None, original_lambda_=None, lambda_=None, iteration=None, transform=None,
                 reporter_filename=None, frame=None, logW=None, **kwargs):
        self.name = name
        self.state = state
        self.original_lambda_ = original_lambda_
        self.lambda_ = lambda_
        self.iteration = iteration
        self.transform = transform
        self.reporter_filename = reporter_filename
        self.frame = frame
        self.logW = logW
        self._energy_cache = {}
        self.__dict__.update(kwargs)

    def __setattr__(self, key, value):
        if key in self._reset_cache_triggers:
            self.resetCache()
        super().__setattr__(key, value)

    def getCachedEnergy(self, lambda_):
        """float : Returns the cached energy at a particular lambda value or None if it has not been cached."""
        energies = [x for x in self._energy_cache if _math.isclose(x, lambda_)]
        if not len(energies):
            return None
        else:
            return self._energy_cache[energies[0]]

    def setCachedEnergy(self, lambda_, energy):
        """Updates the energy cache for a particular lambda value."""
        keys = [x for x in self._energy_cache if _math.isclose(x, lambda_)]
        if not len(keys):
            key = lambda_
        else:
            key = keys[0]
        self._energy_cache[key] = energy

    def setStateKeepCache(self, state):
        """This sets a state whilst keeping the energy cache. This will result in wrong energy values once the state
        changes, so use with caution."""
        super().__setattr__("state", state)

    def resetCache(self):
        self._energy_cache = {}


class WalkerMemo:
    """
    A collection of walkers which supports vectorised operations. This is the primary data container class used by the
    free energy estimators in openmmslicer.fe_estimators.

    Attributes
    ----------
    interpolator : openmmslicer.interpolate.BatchLinearInterp
        A vectorised interpolation function which can be used for batch energy evaluation of all relevant_walkers.
    iterations : numpy.ndarray
        An array containing the corresponding iteration of each relevant_walker.
    lambdas : numpy.ndarray
        An array containing the corresponding lambda value of each relevant_walker.
    lambda_counts : numpy.ndarray
        The number of occurrences of each of the unique_lambdas.
    lock : threading.RLock()
        A thread lock which has to be used by all functions requiring access to the WalkerMemo to prevent it from
        updating in the background if this option is enabled.
    mbar_indices : numpy.ndarray
        An array of the walker indices which sorts them from a time-dependent representation to an MBAR-friendly one.
    relevant_walkers : [openmmslicer.samplers.Walker]
        All walkers with a defined lambda value.
    round_trips : int
        The number of round trips starting from lambda = 1.
    timesteps : int
        The number of timesteps.
    timestep_lambdas
    unique_lambdas : numpy.ndarray
        The sorted unique lambda values of all walkers.
    walkers : [openmmslicer.samplers.Walker]
        All walkers.
    weights : numpy.ndarray
        An array containing the corresponding weight of each relevant_walker.
    """
    def __init__(self):
        self._lock = _threading.RLock()
        self._walker_memo = []
        self._protocol_memo = []
        self._energy_memo = []
        self._energy_matrix_memo = _cachetools.LRUCache(maxsize=1)

    def __getattribute__(self, item):
        if item != "_lock" and hasattr(self, "_lock"):
            with self._lock:
                return super().__getattribute__(item)
        else:
            return super().__getattribute__(item)

    def __setattr__(self, key, value):
        if key != "_lock" and hasattr(self, "_lock"):
            with self._lock:
                super().__setattr__(key, value)
        else:
            super().__setattr__(key, value)

    @_cached_property
    def interpolator(self):
        return _BatchLinearInterp(self._protocol_memo, self._energy_memo, sort=False)

    @_cached_property
    def iterations(self):
        return _np.asarray([w.iteration for w in self.relevant_walkers])

    @_cached_property
    def lambdas(self):
        return _np.asarray([w.lambda_ for w in self.relevant_walkers])

    @_cached_property
    def lambda_counts(self):
        return _np.unique(self.lambdas, return_counts=True)[-1]

    @property
    def lock(self):
        return self._lock

    @_cached_property
    def mbar_indices(self):
        return _np.argsort(_np.concatenate([_np.where(self.lambdas == x)[0] for x in self.unique_lambdas]))

    @_cached_property
    def relevant_walkers(self):
        return [w for w in self._walker_memo if w.lambda_ is not None]

    @_cached_property
    def round_trips(self):
        all_terminal = [x for x in self.timestep_lambdas[1:] if x in [0., 1.]]
        all_terminal = [x[0] for x in _groupby(all_terminal)]
        return max(0, (len(all_terminal) - 1) // 2)

    @_cached_property
    def timesteps(self):
        return self._sorted_unique_hashes.size

    @_cached_property
    def timestep_lambdas(self):
        return self.lambdas[self._hash_indices]

    @_cached_property
    def unique_lambdas(self):
        return _np.sort(_pd.unique(self.lambdas))

    @property
    def walkers(self):
        return self._walker_memo

    @_cached_property
    def weights(self):
        counters = _collections.Counter(self._hashes)
        return _np.asarray([1. / counters[k] for k in self._hashes])

    @_cached_property
    def _hashes(self):
        return _np.asarray([hash((i, lambda_)) for i, lambda_ in zip(self.iterations, self.lambdas)])

    @_cached_property
    def _hash_index_dict(self):
        index_dict = _collections.defaultdict(list)
        for i, hash in enumerate(self._hashes):
            index_dict[hash] += [i]
        index_dict.default_factory = None
        return index_dict

    @_cached_property
    def _hash_indices(self):
        _, indices = _np.unique(self._hashes, return_index=True)
        return _np.sort(indices)

    @_cached_property
    def _sorted_unique_hashes(self):
        # Returning sorted hashes with NumPy is more expensive
        return _pd.unique(self._hashes)

    def resetMemos(self):
        """Explicitly resets all cached properties."""
        for key, value in self.__class__.__dict__.items():
            if isinstance(value, _cached_property):
                self.__dict__.pop(key, None)
        self._energy_matrix_memo.clear()

    def removeWalkers(self, walkers):
        """Removes particular walkers from the memo."""
        if walkers:
            indices = [i for i, w in enumerate(self._walker_memo) if w not in walkers]
            self._walker_memo = [self._walker_memo[i] for i in indices]
            self._protocol_memo = [self._protocol_memo[i] for i in indices if i < len(self._protocol_memo)]
            self._energy_memo = [self._energy_memo[i] for i in indices if i < len(self._energy_memo)]
            self.resetMemos()

    def updateWalkers(self, walkers):
        """Adds walkers to the memo."""
        if walkers:
            self.removeWalkers(walkers)
            self._walker_memo += walkers
            for walker in self._walker_memo:
                if walker.state is not None and walker not in walkers:
                    walker.state = None
            self.resetMemos()

    def updateEnergies(self, ensemble, lambdas):
        """Calculates the energies of all uncached walkers at particular lambda values using an ensemble object."""
        walkers = self.relevant_walkers[len(self._protocol_memo):]
        self._protocol_memo += [_np.sort(lambdas)] * len(walkers)
        self._energy_memo += ensemble.calculateStateEnergies(lambdas, walkers=walkers).T.tolist()
        self.resetMemos()

    def updateWalkersAndEnergies(self, walkers, ensemble, lambdas):
        """Adds walkers and calculates their energies at a particular range of lambda values."""
        self.updateWalkers(walkers)
        self.updateEnergies(ensemble, lambdas)

    #EDIT - Adding the cachedmethod key for energyMatrix as a defined non-anonymous function
    def enermat_key(self, lambdas):
        out_lambdas = []
        for lambda_val in lambdas:
            out_lambdas.append(lambda_val)

        return tuple(out_lambdas)

    @_cachetools.cachedmethod(lambda self: self._energy_matrix_memo, key=enermat_key)
    def energyMatrix(self, lambdas=None):
        """Returns the MBAR energy matrix of all relevant_walkers at a range of lambda values."""
        #print(len(lambdas), len(tuple(lambdas)))
        if lambdas is None:
            lambdas = self.unique_lambdas
        return self.interpolator(_np.asarray(lambdas))

    def walker_to_mbar_indices(self, indices):
        """Converts walker indices to MBAR indices."""
        return indices[_np.argsort(self.mbar_indices[indices])]

    def time_to_walker_indices(self, indices):
        """Converts time indices to walker indices."""
        relevant_hashes = self._sorted_unique_hashes[indices]
        new_indices = _np.asarray(sum([self._hash_index_dict[hash] for hash in relevant_hashes], []))
        return new_indices

    def time_to_mbar_indices(self, indices):
        """Converts time indices to MBAR indices."""
        return self.walker_to_mbar_indices(self.time_to_walker_indices(indices))
